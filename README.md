# Feast Demo: Credit Card Fraud Detection

A simple, end-to-end demo showing how to use **Feast** (a Feature Store) for credit card fraud detection.

## ğŸ“‹ Overview

This use case simulates a realistic ML workflow with Feast:

1. **Offline Store** â€“ Stores historical features for model training
2. **Online Store** â€“ Serves fresh, low-latency features for real-time prediction
3. **Feature Registry** â€“ Centralizes feature metadata and versioning

**Dataset:** [Credit Card Fraud Detection](https://www.kaggle.com/datasets/mlg-ulb/creditcardfraud) (284,807 transactions, 492 frauds)

---

## ğŸ—ï¸ Project Structure

```
feast-fraud-detection/
â”œâ”€â”€ data/                           # Raw & processed data
â”‚   â”œâ”€â”€ creditcard.csv             # Raw Kaggle CSV
â”‚   â””â”€â”€ processed_data.parquet     # Cleaned data with timestamp + ID
â”‚
â”œâ”€â”€ feature_repo/                   # Feast Feature Repository
â”‚   â”œâ”€â”€ feature_store.yaml         # Feast config (registry, online store)
â”‚   â”œâ”€â”€ fraud_features.py          # Entities, Feature Views, sources
â”‚   â””â”€â”€ data/                      # Feast internal state
â”‚       â”œâ”€â”€ registry.db            # Feature Registry (SQLite)
â”‚       â””â”€â”€ online_store.db        # Online Store (SQLite)
â”‚
â”œâ”€â”€ download_data.py               # [1] Download dataset from Kaggle
â”œâ”€â”€ prepare_data.py                # [2] Add event_timestamp & transaction_id
â”œâ”€â”€ train_model.py                 # [3] Train with historical features
â”œâ”€â”€ predict_online.py              # [4] Predict with online features
â”œâ”€â”€ requirements.txt               # Dependencies
â””â”€â”€ README.md                      # You are here
```

---

## ğŸš€ Quickstart

### Step 0 â€” Install Dependencies

```bash
pip install -r requirements.txt
```

### Step 1 â€” Download & Prepare Data

```bash
# Download from Kaggle
python download_data.py

# Create event_timestamp & transaction_id; save to Parquet
python prepare_data.py
```

Output: `data/processed_data.parquet`

### Step 2 â€” Initialize the Feature Store

```bash
cd feature_repo
feast apply
cd ..
```

This will:

* Parse `fraud_features.py` and register your feature definitions
* Create the Feature Registry at `feature_repo/data/registry.db`
* Validate `feature_store.yaml`

### Step 3 â€” Train the Model

```bash
python train_model.py
```

What it does:

1. Pulls **historical features** via `get_historical_features()` (point-in-time correct)
2. Trains a Logistic Regression model
3. Saves the model to `fraud_model.pkl`

### Step 4 â€” Materialize Features (to Online Store)

```bash
cd feature_repo
feast materialize-incremental $(date -u +"%Y-%m-%dT%H:%M:%S")
cd ..
```

**IMPORTANT:** This loads features from the Offline Store (Parquet) into the Online Store (SQLite) so that real-time serving works.

**Alternative (if your shell doesnâ€™t support the date command):**

```bash
cd feature_repo
feast materialize 2020-01-01T00:00:00 2025-12-31T23:59:59
cd ..
```

### Step 5 â€” Online Prediction

```bash
python predict_online.py
```

What it does:

1. Fetches **online features** via `get_online_features()`
2. Runs inference to flag suspected fraudulent transactions

---

## ğŸ“š Feast Concepts Used in This Demo

### 1 Entity (`fraud_features.py`)

```python
transaction = Entity(
    name="transaction_id",
    value_type=ValueType.STRING,
    description="ID of a credit card transaction",
)
```

* An **Entity** is the primary key for features (here, `transaction_id`).

### 2 Feature View (`fraud_features.py`)

```python
transaction_features_v1 = FeatureView(
    name="transaction_features_v1",
    entities=[transaction],
    schema=[Field(name=f"V{i}", dtype=Float32) for i in range(1, 29)] +
           [Field(name="Amount", dtype=Float32)],
    source=fraud_data_source,
    online=True,  # Enable online serving
    ttl=timedelta(days=365),
)
```

* Groups related features (`V1`â€“`V28`, `Amount`)
* `online=True` enables serving from the Online Store
* `ttl` controls time-to-live for online features

### 3 File Source (`fraud_features.py`)

```python
fraud_data_source = FileSource(
    path="../data/processed_data.parquet",
    timestamp_field="event_timestamp",
)
```

* Defines the Offline Store (historical training data)

### 4 Feature Store Config (`feature_store.yaml`)

```yaml
project: fraud_detection_demo
registry: data/registry.db        # SQLite registry
provider: local
online_store:
    type: sqlite                   # SQLite online store
    path: data/online_store.db
```

---

## ğŸ”„ Detailed Workflow

### Training Flow (Offline)

```
processed_data.parquet (Offline Store)
    â†“
get_historical_features()  â† entity_df (transaction_ids + timestamps)
    â†“
Training DataFrame (V1â€“V28, Amount)
    â†“
Train Model â†’ fraud_model.pkl
```

### Serving Flow (Online)

```
processed_data.parquet
    â†“  feast materialize
Online Store (SQLite) â€” keyed by transaction_id
    â†“
get_online_features()  â† entity_rows (transaction_ids)
    â†“
Real-time Features
    â†“
Prediction
```